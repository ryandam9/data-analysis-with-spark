{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82886ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "title: \"Meta Kaggle Overview\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc9ae91",
   "metadata": {},
   "source": [
    "# Meta Kaggle Overview\n",
    "Kaggle's public data on competitions, users, submission scores, and kernels\n",
    "\n",
    "- https://www.kaggle.com/datasets/kaggle/meta-kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6c5151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror {\n",
       "    font-size: 14px; \n",
       "    font-family: 'Jetbrains Mono';\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror {\n",
    "    font-size: 14px; \n",
    "    font-family: 'Jetbrains Mono';\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b3721d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e031f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8231d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82f092d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e6a650c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/13 14:27:11 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"meta-kaggle-data-analysis\")\n",
    "        .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb5979c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.20:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x107c69ed0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b0dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files_path = \"/Volumes/samsung-2tb/rk/downloads/archive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b89bfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 54139600\r\n",
      "-rw-rw-r--@ 1 rk  staff    12G 11 Aug 11:20 EpisodeAgents.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   4.0G 11 Aug 11:43 UserAchievements.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   3.3G 11 Aug 11:36 Episodes.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   1.5G 11 Aug 11:40 Submissions.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   1.3G 11 Aug 11:39 KernelVersions.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   796M 11 Aug 11:45 Users.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   748M 11 Aug 11:18 DatasetVersions.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   663M 11 Aug 11:38 ForumMessages.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   505M 11 Aug 11:42 Teams.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   279M 11 Aug 11:42 TeamMemberships.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   198M 11 Aug 11:39 KernelVersionDatasetSources.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   156M 11 Aug 11:40 KernelVotes.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   144M 11 Aug 11:40 Kernels.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   130M 11 Aug 11:38 ForumMessageVotes.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    64M 11 Aug 11:19 DatasetVotes.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    51M 11 Aug 11:45 UserFollowers.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    46M 11 Aug 11:39 ForumTopics.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    39M 11 Aug 11:39 KernelVersionCompetitionSources.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    29M 11 Aug 11:19 Datasets.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    21M 11 Aug 11:39 KernelTags.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    19M 11 Aug 11:39 KernelVersionKernelSources.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    13M 11 Aug 11:19 Datasources.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    11M 11 Aug 11:39 Forums.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   7.6M 11 Aug 11:18 DatasetTasks.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   6.5M 11 Aug 11:17 DatasetTags.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   2.5M 11 Aug 11:17 Competitions.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   654K 11 Aug 11:17 DatasetTaskSubmissions.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   260K 11 Aug 11:40 Organizations.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    93K 11 Aug 11:42 Tags.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    62K 11 Aug 11:45 UserOrganizations.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff    19K 11 Aug 11:17 CompetitionTags.csv\r\n",
      "-rw-rw-r--@ 1 rk  staff   410B 11 Aug 11:39 KernelLanguages.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lhS $data_files_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd16aee",
   "metadata": {},
   "source": [
    "- `EpisodeAgents.csv` is the biggest file (~12G)\n",
    "- There are 4 more files that are bigger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f36c0",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353dae1f",
   "metadata": {},
   "source": [
    "## Gather column names of all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70fc57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6686b28d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Datasets & Column names\n",
      "Competitions.csv\n",
      "['Id', 'Slug', 'Title', 'Subtitle', 'HostSegmentTitle', 'ForumId', 'OrganizationId', 'EnabledDate', 'DeadlineDate', 'ProhibitNewEntrantsDeadlineDate', 'TeamMergerDeadlineDate', 'TeamModelDeadlineDate', 'ModelSubmissionDeadlineDate', 'FinalLeaderboardHasBeenVerified', 'HasKernels', 'OnlyAllowKernelSubmissions', 'HasLeaderboard', 'LeaderboardPercentage', 'LeaderboardDisplayFormat', 'EvaluationAlgorithmAbbreviation', 'EvaluationAlgorithmName', 'EvaluationAlgorithmDescription', 'EvaluationAlgorithmIsMax', 'MaxDailySubmissions', 'NumScoredSubmissions', 'MaxTeamSize', 'BanTeamMergers', 'EnableTeamModels', 'RewardType', 'RewardQuantity', 'NumPrizes', 'UserRankMultiplier', 'CanQualifyTiers', 'TotalTeams', 'TotalCompetitors', 'TotalSubmissions', 'ValidationSetName', 'ValidationSetValue', 'EnableSubmissionModelHashes', 'EnableSubmissionModelAttachments', 'HostName', 'CompetitionTypeId']\n",
      "\n",
      "CompetitionTags.csv\n",
      "['Id', 'CompetitionId', 'TagId']\n",
      "\n",
      "Datasets.csv\n",
      "['Id', 'CreatorUserId', 'OwnerUserId', 'OwnerOrganizationId', 'CurrentDatasetVersionId', 'CurrentDatasourceVersionId', 'ForumId', 'Type', 'CreationDate', 'LastActivityDate', 'TotalViews', 'TotalDownloads', 'TotalVotes', 'TotalKernels']\n",
      "\n",
      "DatasetTags.csv\n",
      "['Id', 'DatasetId', 'TagId']\n",
      "\n",
      "DatasetTasks.csv\n",
      "['Id', 'DatasetId', 'OwnerUserId', 'CreationDate', 'Description', 'ForumId', 'Title', 'Subtitle', 'Deadline', 'TotalVotes']\n",
      "\n",
      "DatasetTaskSubmissions.csv\n",
      "['Id', 'DatasetTaskId', 'SubmittedUserId', 'CreationDate', 'KernelId', 'DatasetId', 'AcceptedDate']\n",
      "\n",
      "DatasetVersions.csv\n",
      "['Id', 'DatasetId', 'DatasourceVersionId', 'CreatorUserId', 'LicenseName', 'CreationDate', 'VersionNumber', 'Title', 'Slug', 'Subtitle', 'Description', 'VersionNotes', 'TotalCompressedBytes', 'TotalUncompressedBytes']\n",
      "\n",
      "DatasetVotes.csv\n",
      "['Id', 'UserId', 'DatasetVersionId', 'VoteDate']\n",
      "\n",
      "Datasources.csv\n",
      "['Id', 'CreatorUserId', 'CreationDate', 'Type', 'CurrentDatasourceVersionId']\n",
      "\n",
      "EpisodeAgents.csv\n",
      "['Id', 'EpisodeId', 'Index', 'Reward', 'State', 'SubmissionId', 'InitialConfidence', 'InitialScore', 'UpdatedConfidence', 'UpdatedScore']\n",
      "\n",
      "Episodes.csv\n",
      "['Id', 'Type', 'CompetitionId', 'CreateTime', 'EndTime']\n",
      "\n",
      "ForumMessages.csv\n",
      "['Id', 'ForumTopicId', 'PostUserId', 'PostDate', 'ReplyToForumMessageId', 'Message', 'Medal', 'MedalAwardDate']\n",
      "\n",
      "ForumMessageVotes.csv\n",
      "['Id', 'ForumMessageId', 'FromUserId', 'ToUserId', 'VoteDate']\n",
      "\n",
      "Forums.csv\n",
      "['Id', 'ParentForumId', 'Title']\n",
      "\n",
      "ForumTopics.csv\n",
      "['Id', 'ForumId', 'KernelId', 'LastForumMessageId', 'FirstForumMessageId', 'CreationDate', 'LastCommentDate', 'Title', 'IsSticky', 'TotalViews', 'Score', 'TotalMessages', 'TotalReplies']\n",
      "\n",
      "KernelLanguages.csv\n",
      "['Id', 'Name', 'DisplayName', 'IsNotebook']\n",
      "\n",
      "Kernels.csv\n",
      "['Id', 'AuthorUserId', 'CurrentKernelVersionId', 'ForkParentKernelVersionId', 'ForumTopicId', 'FirstKernelVersionId', 'CreationDate', 'EvaluationDate', 'MadePublicDate', 'IsProjectLanguageTemplate', 'CurrentUrlSlug', 'Medal', 'MedalAwardDate', 'TotalViews', 'TotalComments', 'TotalVotes']\n",
      "\n",
      "KernelTags.csv\n",
      "['Id', 'KernelId', 'TagId']\n",
      "\n",
      "KernelVersionCompetitionSources.csv\n",
      "['Id', 'KernelVersionId', 'SourceCompetitionId']\n",
      "\n",
      "KernelVersionDatasetSources.csv\n",
      "['Id', 'KernelVersionId', 'SourceDatasetVersionId']\n",
      "\n",
      "KernelVersionKernelSources.csv\n",
      "['Id', 'KernelVersionId', 'SourceKernelVersionId']\n",
      "\n",
      "KernelVersions.csv\n",
      "['Id', 'ScriptId', 'ParentScriptVersionId', 'ScriptLanguageId', 'AuthorUserId', 'CreationDate', 'VersionNumber', 'Title', 'EvaluationDate', 'IsChange', 'TotalLines', 'LinesInsertedFromPrevious', 'LinesChangedFromPrevious', 'LinesUnchangedFromPrevious', 'LinesInsertedFromFork', 'LinesDeletedFromFork', 'LinesChangedFromFork', 'LinesUnchangedFromFork', 'TotalVotes']\n",
      "\n",
      "KernelVotes.csv\n",
      "['Id', 'UserId', 'KernelVersionId', 'VoteDate']\n",
      "\n",
      "Organizations.csv\n",
      "['Id', 'Name', 'Slug', 'CreationDate', 'Description']\n",
      "\n",
      "Submissions.csv\n",
      "['Id', 'SubmittedUserId', 'TeamId', 'SourceKernelVersionId', 'SubmissionDate', 'ScoreDate', 'IsAfterDeadline', 'PublicScoreLeaderboardDisplay', 'PublicScoreFullPrecision', 'PrivateScoreLeaderboardDisplay', 'PrivateScoreFullPrecision']\n",
      "\n",
      "Tags.csv\n",
      "['Id', 'ParentTagId', 'Name', 'Slug', 'FullPath', 'Description', 'DatasetCount', 'CompetitionCount', 'KernelCount']\n",
      "\n",
      "TeamMemberships.csv\n",
      "['Id', 'TeamId', 'UserId', 'RequestDate']\n",
      "\n",
      "Teams.csv\n",
      "['Id', 'CompetitionId', 'TeamLeaderId', 'TeamName', 'ScoreFirstSubmittedDate', 'LastSubmissionDate', 'PublicLeaderboardSubmissionId', 'PrivateLeaderboardSubmissionId', 'IsBenchmark', 'Medal', 'MedalAwardDate', 'PublicLeaderboardRank', 'PrivateLeaderboardRank', 'WriteUpForumTopicId']\n",
      "\n",
      "UserAchievements.csv\n",
      "['Id', 'UserId', 'AchievementType', 'Tier', 'TierAchievementDate', 'Points', 'CurrentRanking', 'HighestRanking', 'TotalGold', 'TotalSilver', 'TotalBronze']\n",
      "\n",
      "UserFollowers.csv\n",
      "['Id', 'UserId', 'FollowingUserId', 'CreationDate']\n",
      "\n",
      "UserOrganizations.csv\n",
      "['Id', 'UserId', 'OrganizationId', 'JoinDate']\n",
      "\n",
      "Users.csv\n",
      "['Id', 'UserName', 'DisplayName', 'RegisterDate', 'PerformanceTier']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemas = dict()\n",
    "\n",
    "# Iterate through CSV files in the directory\n",
    "for filename in os.listdir(data_files_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_files_path, filename)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            headers = next(reader)  # Get the header row\n",
    "            \n",
    "            schemas[filename] = headers\n",
    "            \n",
    "print(\"All Datasets & Column names\")\n",
    "\n",
    "for filename, schema in schemas.items():\n",
    "    print(filename)\n",
    "    print(schema)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e4d415",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0dd47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
